{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import tempfile\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Generate Code Quality Scores Using `Flake8`\n",
    "\n",
    "Since our dataset now includes the actual code for each function, we can use `Flake8` to objectively assess code quality.\n",
    "\n",
    "### Why use `Flake8`?\n",
    "- It's a **widely-used Python linter** that detects code smells, complexity, unused variables, and more.\n",
    "- It gives a **numeric score out of 10** summarizing the overall code quality.\n",
    "- This gives us an **automated, data-driven way** to assign quality scores instead of relying on hand-crafted heuristics.\n",
    "\n",
    "### What we’ll do:\n",
    "- Write each function’s code to a temporary Python file.\n",
    "- Run `flake8` on that file.\n",
    "- Parse the output to extract the numeric score.\n",
    "- Store the score in a new column called `quality_score`.\n",
    "\n",
    "### Note:\n",
    "- This step has already been done in another script file named 'Score_quality.py'\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/interim/function_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                             2\n",
       "node_type                        0\n",
       "file_path                        0\n",
       "code_snippet                     0\n",
       "repo_name                        0\n",
       "repo_stars                       0\n",
       "repo_forks                       0\n",
       "repo_watchers                    0\n",
       "repo_language                    0\n",
       "repo_created_at                  0\n",
       "repo_last_updated                0\n",
       "repo_topics                      0\n",
       "loc                              0\n",
       "num_args                         0\n",
       "num_returns                      0\n",
       "num_variables                    0\n",
       "num_function_calls               0\n",
       "has_decorators                   0\n",
       "uses_globals                     0\n",
       "is_recursive                     0\n",
       "estimated_branches          108641\n",
       "estimated_difficulty             0\n",
       "estimated_bugs                   0\n",
       "has_docstring                    0\n",
       "docstring_length                 0\n",
       "num_comments                     0\n",
       "name_length                      0\n",
       "is_name_well_formed              0\n",
       "bad_variable_names_count         0\n",
       "max_return_length                0\n",
       "quality                     108641\n",
       "estimated_complexity             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    \"name\",\n",
    "    \"node_type\",\n",
    "    \"file_path\",\n",
    "    \"repo_name\",\n",
    "    \"repo_stars\",\n",
    "    \"repo_forks\",\n",
    "    \"repo_watchers\",\n",
    "    \"repo_language\",\n",
    "    \"repo_created_at\",\n",
    "    \"repo_last_updated\",\n",
    "    \"repo_topics\",\n",
    "    \"estimated_branches\",  # all values null\n",
    "    \"quality\"              # all values null will add it later when the model is finished\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code_snippet                 object\n",
       "loc                           int64\n",
       "num_args                      int64\n",
       "num_returns                   int64\n",
       "num_variables                 int64\n",
       "num_function_calls            int64\n",
       "has_decorators                 bool\n",
       "uses_globals                   bool\n",
       "is_recursive                   bool\n",
       "estimated_difficulty        float64\n",
       "estimated_bugs              float64\n",
       "has_docstring                  bool\n",
       "docstring_length              int64\n",
       "num_comments                  int64\n",
       "name_length                   int64\n",
       "is_name_well_formed            bool\n",
       "bad_variable_names_count      int64\n",
       "max_return_length             int64\n",
       "estimated_complexity          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code_snippet                0\n",
       "loc                         0\n",
       "num_args                    0\n",
       "num_returns                 0\n",
       "num_variables               0\n",
       "num_function_calls          0\n",
       "has_decorators              0\n",
       "uses_globals                0\n",
       "is_recursive                0\n",
       "estimated_difficulty        0\n",
       "estimated_bugs              0\n",
       "has_docstring               0\n",
       "docstring_length            0\n",
       "num_comments                0\n",
       "name_length                 0\n",
       "is_name_well_formed         0\n",
       "bad_variable_names_count    0\n",
       "max_return_length           0\n",
       "estimated_complexity        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_snippet</th>\n",
       "      <th>loc</th>\n",
       "      <th>num_args</th>\n",
       "      <th>num_returns</th>\n",
       "      <th>num_variables</th>\n",
       "      <th>num_function_calls</th>\n",
       "      <th>has_decorators</th>\n",
       "      <th>uses_globals</th>\n",
       "      <th>is_recursive</th>\n",
       "      <th>estimated_difficulty</th>\n",
       "      <th>estimated_bugs</th>\n",
       "      <th>has_docstring</th>\n",
       "      <th>docstring_length</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>name_length</th>\n",
       "      <th>is_name_well_formed</th>\n",
       "      <th>bad_variable_names_count</th>\n",
       "      <th>max_return_length</th>\n",
       "      <th>estimated_complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>def __eq__(self, other):\\n        return all(\\...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.004644</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>def __ne__(self, other):\\n        return not s...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>def __enter__(self):\\n        return self</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>def __exit__(self, *args):\\n        self.close()</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>def response_handler(sock):\\n            consu...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108110</th>\n",
       "      <td>def cedar_dec(func):\\n        @wraps(func)\\n  ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108117</th>\n",
       "      <td>def example(req, test='default', *, loop='lol'...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108122</th>\n",
       "      <td>def cedar_wrapper(*a, **kw):\\n            retu...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108291</th>\n",
       "      <td>def client_connect():\\n        clientsock = so...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108556</th>\n",
       "      <td>def __len__(self):\\n        return len(self.le...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3331 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             code_snippet  loc  num_args  \\\n",
       "45      def __eq__(self, other):\\n        return all(\\...    7         2   \n",
       "46      def __ne__(self, other):\\n        return not s...    2         2   \n",
       "163             def __enter__(self):\\n        return self    2         1   \n",
       "164      def __exit__(self, *args):\\n        self.close()    2         1   \n",
       "525     def response_handler(sock):\\n            consu...    7         1   \n",
       "...                                                   ...  ...       ...   \n",
       "108110  def cedar_dec(func):\\n        @wraps(func)\\n  ...    5         1   \n",
       "108117  def example(req, test='default', *, loop='lol'...    2         2   \n",
       "108122  def cedar_wrapper(*a, **kw):\\n            retu...    2         0   \n",
       "108291  def client_connect():\\n        clientsock = so...    4         0   \n",
       "108556  def __len__(self):\\n        return len(self.le...    2         1   \n",
       "\n",
       "        num_returns  num_variables  num_function_calls  has_decorators  \\\n",
       "45                1              0                   3           False   \n",
       "46                1              0                   0           False   \n",
       "163               1              0                   0           False   \n",
       "164               0              0                   1           False   \n",
       "525               0              0                   2           False   \n",
       "...             ...            ...                 ...             ...   \n",
       "108110            2              0                   2           False   \n",
       "108117            1              0                   0           False   \n",
       "108122            1              0                   2            True   \n",
       "108291            1              2                   2           False   \n",
       "108556            1              0                   2           False   \n",
       "\n",
       "        uses_globals  is_recursive  estimated_difficulty  estimated_bugs  \\\n",
       "45             False         False                   0.5        0.004644   \n",
       "46             False         False                   1.0        0.003870   \n",
       "163            False         False                   0.0        0.000000   \n",
       "164            False         False                   0.0        0.000000   \n",
       "525            False         False                   0.0        0.000000   \n",
       "...              ...           ...                   ...             ...   \n",
       "108110         False         False                   0.0        0.000000   \n",
       "108117         False         False                   0.0        0.000000   \n",
       "108122         False         False                   0.0        0.000000   \n",
       "108291         False         False                   0.0        0.000000   \n",
       "108556         False         False                   0.5        0.001585   \n",
       "\n",
       "        has_docstring  docstring_length  num_comments  name_length  \\\n",
       "45              False                 0             0            6   \n",
       "46              False                 0             0            6   \n",
       "163             False                 0             0            9   \n",
       "164             False                 0             0            8   \n",
       "525             False                 0             0           16   \n",
       "...               ...               ...           ...          ...   \n",
       "108110          False                 0             0            9   \n",
       "108117          False                 0             0            7   \n",
       "108122          False                 0             0           13   \n",
       "108291          False                 0             0           14   \n",
       "108556          False                 0             0            7   \n",
       "\n",
       "        is_name_well_formed  bad_variable_names_count  max_return_length  \\\n",
       "45                     True                         0                107   \n",
       "46                     True                         0                 17   \n",
       "163                    True                         0                  4   \n",
       "164                    True                         0                  0   \n",
       "525                    True                         0                  0   \n",
       "...                     ...                       ...                ...   \n",
       "108110                 True                         0                 37   \n",
       "108117                 True                         0                  4   \n",
       "108122                 True                         0                 37   \n",
       "108291                 True                         0                  6   \n",
       "108556                 True                         0                 32   \n",
       "\n",
       "        estimated_complexity  \n",
       "45                         1  \n",
       "46                         1  \n",
       "163                        1  \n",
       "164                        1  \n",
       "525                        1  \n",
       "...                      ...  \n",
       "108110                     1  \n",
       "108117                     1  \n",
       "108122                     1  \n",
       "108291                     1  \n",
       "108556                     1  \n",
       "\n",
       "[3331 rows x 19 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = df.duplicated()\n",
    "df[duplicates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if the quality_score column has any null values if so remove them\n",
    "df = df[df['quality_score'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 5: Bin Scores into Quality Labels\n",
    "\n",
    "Once we have `quality_score`, we classify it into discrete quality levels:\n",
    "- **0–3** → `bad`\n",
    "- **3–6** → `moderate`\n",
    "- **6–8** → `good`\n",
    "- **8–10** → `excellent`\n",
    "\n",
    "These categories will be stored in a new column: `quality_label`.\n",
    "\n",
    "This prepares our dataset for classification tasks, where the model will learn to predict the label based on features.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quality_label'] = pd.cut(\n",
    "    df['quality_score'],\n",
    "    bins=[-float('inf'), 3, 6, 8, float('inf')],\n",
    "    labels=['bad', 'moderate', 'good', 'excellent']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "quality_label\n",
      "bad          0\n",
      "moderate     0\n",
      "good         0\n",
      "excellent    0\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(df['quality_label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 6: Train-Test Split\n",
    "\n",
    "After scoring and labeling, we divide the dataset into **training** and **testing** subsets:\n",
    "- **80%** of the data is used for training,\n",
    "- **20%** is reserved for testing,\n",
    "- We use `stratify=y` to maintain class proportions.\n",
    "\n",
    "This split ensures that we can evaluate model performance fairly and avoid data leakage.\n",
    "\n",
    "We will later save the splits into `data/processed/` for reuse during model training and evaluation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m X = df.drop(columns=[\u001b[33m'\u001b[39m\u001b[33mquality_score\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mquality_label\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      4\u001b[39m y = df[\u001b[33m'\u001b[39m\u001b[33mquality_label\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m X_train, X_test, y_train, y_test = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstratify\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nour\\Desktop\\Project\\Project2\\code-quality-assessor\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nour\\Desktop\\Project\\Project2\\code-quality-assessor\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2851\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[39m\n\u001b[32m   2848\u001b[39m arrays = indexable(*arrays)\n\u001b[32m   2850\u001b[39m n_samples = _num_samples(arrays[\u001b[32m0\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m2851\u001b[39m n_train, n_test = \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2852\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.25\u001b[39;49m\n\u001b[32m   2853\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2855\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m   2856\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nour\\Desktop\\Project\\Project2\\code-quality-assessor\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2481\u001b[39m, in \u001b[36m_validate_shuffle_split\u001b[39m\u001b[34m(n_samples, test_size, train_size, default_test_size)\u001b[39m\n\u001b[32m   2478\u001b[39m n_train, n_test = \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[32m   2480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_train == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2481\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2482\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2483\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2484\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33maforementioned parameters.\u001b[39m\u001b[33m\"\u001b[39m.format(n_samples, test_size, train_size)\n\u001b[32m   2485\u001b[39m     )\n\u001b[32m   2487\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[31mValueError\u001b[39m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns=['quality_score', 'quality_label'])\n",
    "y = df['quality_label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 7: Feature Preprocessing – Scaling and Encoding\n",
    "\n",
    "Now that we’ve labeled our dataset, the next step is to **prepare the features** for use in machine learning models.\n",
    "\n",
    "### Why this step is important:\n",
    "- Some models, like **Neural Networks** and **Transformers**, are sensitive to the scale of input features.\n",
    "- **Random Forests** don’t need scaling, but we’ll preprocess everything uniformly to keep workflows consistent.\n",
    "- Boolean features like `has_docstring` and `uses_globals` can be used directly (0 or 1), but must be properly handled in the pipeline.\n",
    "\n",
    "### What we’ll do:\n",
    "- **Scale** all numerical features using `StandardScaler` (mean = 0, std = 1).\n",
    "- **Pass through** all boolean features (they're already numeric).\n",
    "\n",
    "We use `ColumnTransformer` to apply different preprocessing steps to different columns.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate numeric and boolean features\n",
    "numeric_features = df.select_dtypes(include=['int64', 'float64']).drop(columns=['quality_score']).columns.tolist()\n",
    "boolean_features = df.select_dtypes(include=['bool']).columns.tolist()\n",
    "\n",
    "# Create preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),  # Scale numeric features\n",
    "        ('bool', 'passthrough', boolean_features)     # Keep boolean features as-is\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 8: Train-Test Split and Dataset Saving\n",
    "\n",
    "Once the features are ready, we’ll split the dataset into **training** and **testing** sets.\n",
    "\n",
    "### Why we do this:\n",
    "- To **evaluate** model performance fairly.\n",
    "- To **prevent data leakage** — the model should never \"see\" the test data during training.\n",
    "- To **reuse** the same splits for all models and experiments.\n",
    "\n",
    "### What we’ll do:\n",
    "- Split 80% for training, 20% for testing using `train_test_split()`.\n",
    "- Use `stratify=y` to preserve class proportions across splits.\n",
    "- Save the resulting datasets (`X_train`, `X_test`, `y_train`, `y_test`) to the `data/processed/` folder so they can be easily loaded later in the training and evaluation notebooks.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the features and target \n",
    "X = df.drop(columns=['quality_score', 'quality_label'])\n",
    "y = df['quality_label']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "X_train.to_csv(\"../data/processed/X_train.csv\", index=False)\n",
    "X_test.to_csv(\"../data/processed/X_test.csv\", index=False)\n",
    "y_train.to_csv(\"../data/processed/y_train.csv\", index=False)\n",
    "y_test.to_csv(\"../data/processed/y_test.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
