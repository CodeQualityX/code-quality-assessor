{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import tempfile\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw/function_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                             2\n",
       "node_type                        0\n",
       "file_path                        0\n",
       "code_snippet                     0\n",
       "repo_name                        0\n",
       "repo_stars                       0\n",
       "repo_forks                       0\n",
       "repo_watchers                    0\n",
       "repo_language                    0\n",
       "repo_created_at                  0\n",
       "repo_last_updated                0\n",
       "repo_topics                      0\n",
       "loc                              0\n",
       "num_args                         0\n",
       "num_returns                      0\n",
       "num_variables                    0\n",
       "num_function_calls               0\n",
       "has_decorators                   0\n",
       "uses_globals                     0\n",
       "is_recursive                     0\n",
       "estimated_branches          108641\n",
       "estimated_difficulty             0\n",
       "estimated_bugs                   0\n",
       "has_docstring                    0\n",
       "docstring_length                 0\n",
       "num_comments                     0\n",
       "name_length                      0\n",
       "is_name_well_formed              0\n",
       "bad_variable_names_count         0\n",
       "max_return_length                0\n",
       "quality                     108641\n",
       "estimated_complexity             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    \"name\",\n",
    "    \"node_type\",\n",
    "    \"file_path\",\n",
    "    \"repo_name\",\n",
    "    \"repo_stars\",\n",
    "    \"repo_forks\",\n",
    "    \"repo_watchers\",\n",
    "    \"repo_language\",\n",
    "    \"repo_created_at\",\n",
    "    \"repo_last_updated\",\n",
    "    \"repo_topics\",\n",
    "    \"estimated_branches\",  # all values null\n",
    "    \"quality\"              # all values null will add it later when the model is finished\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code_snippet                 object\n",
       "loc                           int64\n",
       "num_args                      int64\n",
       "num_returns                   int64\n",
       "num_variables                 int64\n",
       "num_function_calls            int64\n",
       "has_decorators                 bool\n",
       "uses_globals                   bool\n",
       "is_recursive                   bool\n",
       "estimated_difficulty        float64\n",
       "estimated_bugs              float64\n",
       "has_docstring                  bool\n",
       "docstring_length              int64\n",
       "num_comments                  int64\n",
       "name_length                   int64\n",
       "is_name_well_formed            bool\n",
       "bad_variable_names_count      int64\n",
       "max_return_length             int64\n",
       "estimated_complexity          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code_snippet                0\n",
       "loc                         0\n",
       "num_args                    0\n",
       "num_returns                 0\n",
       "num_variables               0\n",
       "num_function_calls          0\n",
       "has_decorators              0\n",
       "uses_globals                0\n",
       "is_recursive                0\n",
       "estimated_difficulty        0\n",
       "estimated_bugs              0\n",
       "has_docstring               0\n",
       "docstring_length            0\n",
       "num_comments                0\n",
       "name_length                 0\n",
       "is_name_well_formed         0\n",
       "bad_variable_names_count    0\n",
       "max_return_length           0\n",
       "estimated_complexity        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_snippet</th>\n",
       "      <th>loc</th>\n",
       "      <th>num_args</th>\n",
       "      <th>num_returns</th>\n",
       "      <th>num_variables</th>\n",
       "      <th>num_function_calls</th>\n",
       "      <th>has_decorators</th>\n",
       "      <th>uses_globals</th>\n",
       "      <th>is_recursive</th>\n",
       "      <th>estimated_difficulty</th>\n",
       "      <th>estimated_bugs</th>\n",
       "      <th>has_docstring</th>\n",
       "      <th>docstring_length</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>name_length</th>\n",
       "      <th>is_name_well_formed</th>\n",
       "      <th>bad_variable_names_count</th>\n",
       "      <th>max_return_length</th>\n",
       "      <th>estimated_complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>def __eq__(self, other):\\n        return all(\\...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.004644</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>def __ne__(self, other):\\n        return not s...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>def __enter__(self):\\n        return self</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>def __exit__(self, *args):\\n        self.close()</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>def response_handler(sock):\\n            consu...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108110</th>\n",
       "      <td>def cedar_dec(func):\\n        @wraps(func)\\n  ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108117</th>\n",
       "      <td>def example(req, test='default', *, loop='lol'...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108122</th>\n",
       "      <td>def cedar_wrapper(*a, **kw):\\n            retu...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108291</th>\n",
       "      <td>def client_connect():\\n        clientsock = so...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108556</th>\n",
       "      <td>def __len__(self):\\n        return len(self.le...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3331 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             code_snippet  loc  num_args  \\\n",
       "45      def __eq__(self, other):\\n        return all(\\...    7         2   \n",
       "46      def __ne__(self, other):\\n        return not s...    2         2   \n",
       "163             def __enter__(self):\\n        return self    2         1   \n",
       "164      def __exit__(self, *args):\\n        self.close()    2         1   \n",
       "525     def response_handler(sock):\\n            consu...    7         1   \n",
       "...                                                   ...  ...       ...   \n",
       "108110  def cedar_dec(func):\\n        @wraps(func)\\n  ...    5         1   \n",
       "108117  def example(req, test='default', *, loop='lol'...    2         2   \n",
       "108122  def cedar_wrapper(*a, **kw):\\n            retu...    2         0   \n",
       "108291  def client_connect():\\n        clientsock = so...    4         0   \n",
       "108556  def __len__(self):\\n        return len(self.le...    2         1   \n",
       "\n",
       "        num_returns  num_variables  num_function_calls  has_decorators  \\\n",
       "45                1              0                   3           False   \n",
       "46                1              0                   0           False   \n",
       "163               1              0                   0           False   \n",
       "164               0              0                   1           False   \n",
       "525               0              0                   2           False   \n",
       "...             ...            ...                 ...             ...   \n",
       "108110            2              0                   2           False   \n",
       "108117            1              0                   0           False   \n",
       "108122            1              0                   2            True   \n",
       "108291            1              2                   2           False   \n",
       "108556            1              0                   2           False   \n",
       "\n",
       "        uses_globals  is_recursive  estimated_difficulty  estimated_bugs  \\\n",
       "45             False         False                   0.5        0.004644   \n",
       "46             False         False                   1.0        0.003870   \n",
       "163            False         False                   0.0        0.000000   \n",
       "164            False         False                   0.0        0.000000   \n",
       "525            False         False                   0.0        0.000000   \n",
       "...              ...           ...                   ...             ...   \n",
       "108110         False         False                   0.0        0.000000   \n",
       "108117         False         False                   0.0        0.000000   \n",
       "108122         False         False                   0.0        0.000000   \n",
       "108291         False         False                   0.0        0.000000   \n",
       "108556         False         False                   0.5        0.001585   \n",
       "\n",
       "        has_docstring  docstring_length  num_comments  name_length  \\\n",
       "45              False                 0             0            6   \n",
       "46              False                 0             0            6   \n",
       "163             False                 0             0            9   \n",
       "164             False                 0             0            8   \n",
       "525             False                 0             0           16   \n",
       "...               ...               ...           ...          ...   \n",
       "108110          False                 0             0            9   \n",
       "108117          False                 0             0            7   \n",
       "108122          False                 0             0           13   \n",
       "108291          False                 0             0           14   \n",
       "108556          False                 0             0            7   \n",
       "\n",
       "        is_name_well_formed  bad_variable_names_count  max_return_length  \\\n",
       "45                     True                         0                107   \n",
       "46                     True                         0                 17   \n",
       "163                    True                         0                  4   \n",
       "164                    True                         0                  0   \n",
       "525                    True                         0                  0   \n",
       "...                     ...                       ...                ...   \n",
       "108110                 True                         0                 37   \n",
       "108117                 True                         0                  4   \n",
       "108122                 True                         0                 37   \n",
       "108291                 True                         0                  6   \n",
       "108556                 True                         0                 32   \n",
       "\n",
       "        estimated_complexity  \n",
       "45                         1  \n",
       "46                         1  \n",
       "163                        1  \n",
       "164                        1  \n",
       "525                        1  \n",
       "...                      ...  \n",
       "108110                     1  \n",
       "108117                     1  \n",
       "108122                     1  \n",
       "108291                     1  \n",
       "108556                     1  \n",
       "\n",
       "[3331 rows x 19 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = df.duplicated()\n",
    "df[duplicates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate rows\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4: Generate Code Quality Scores Using `pylint`\n",
    "\n",
    "Since our dataset now includes the actual code for each function, we can use `pylint` to objectively assess code quality.\n",
    "\n",
    "### Why use `pylint`?\n",
    "- It's a **widely-used Python linter** that detects code smells, complexity, unused variables, and more.\n",
    "- It gives a **numeric score out of 10** summarizing the overall code quality.\n",
    "- This gives us an **automated, data-driven way** to assign quality scores instead of relying on hand-crafted heuristics.\n",
    "\n",
    "### What we’ll do:\n",
    "- Write each function’s code to a temporary Python file.\n",
    "- Run `pylint` on that file.\n",
    "- Parse the output to extract the numeric score.\n",
    "- Store the score in a new column called `quality_score`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pylint_score(code_string):\n",
    "    try:\n",
    "        with tempfile.NamedTemporaryFile('w', suffix='.py', delete=False, encoding='utf-8') as tmp:\n",
    "            tmp.write(code_string)\n",
    "            tmp_path = tmp.name\n",
    "\n",
    "        result = subprocess.run(\n",
    "            ['pylint', tmp_path, '--score=y'], \n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "\n",
    "        output = result.stdout\n",
    "        for line in output.splitlines():\n",
    "            match = re.search(r\"rated at ([0-9.]+)/10\", line)\n",
    "            if match:\n",
    "                return float(match.group(1))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Parallelized Code Quality Scoring with Pylint\n",
    "\n",
    "Since scoring each function using `pylint` is slow (each one runs as a separate subprocess), we use Python’s `multiprocessing` module to run the scoring in parallel across multiple CPU cores.\n",
    "\n",
    "This significantly speeds up the process of generating `quality_score` for every `code_snippet` in the dataset.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# tqdm used for progress bar for my sanity sake \n",
    "def run_parallel_with_tqdm(func, data, num_workers=None):\n",
    "    from multiprocessing import Pool, cpu_count\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    num_workers = num_workers or cpu_count()\n",
    "    results = []\n",
    "    \n",
    "    with Pool(processes=num_workers) as pool:\n",
    "        with tqdm(total=len(data)) as pbar:\n",
    "            for result in pool.imap(func, data):\n",
    "                results.append(result)\n",
    "                pbar.update(1)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Run and assign\\\n",
    "df_small = df.head(50)\n",
    "\n",
    "df_small['quality_score'] = run_parallel_with_tqdm(get_pylint_score, df_small['code_snippet'].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 5: Bin Scores into Quality Labels\n",
    "\n",
    "Once we have `quality_score`, we classify it into discrete quality levels:\n",
    "- **0–3** → `bad`\n",
    "- **3–6** → `moderate`\n",
    "- **6–8** → `good`\n",
    "- **8–10** → `excellent`\n",
    "\n",
    "These categories will be stored in a new column: `quality_label`.\n",
    "\n",
    "This prepares our dataset for classification tasks, where the model will learn to predict the label based on features.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'quality_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nour\\Desktop\\Project\\Project2\\code-quality-assessor\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'quality_score'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mquality_label\u001b[39m\u001b[33m'\u001b[39m] = pd.cut(\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mquality_score\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[32m      3\u001b[39m     bins=[-\u001b[38;5;28mfloat\u001b[39m(\u001b[33m'\u001b[39m\u001b[33minf\u001b[39m\u001b[33m'\u001b[39m), \u001b[32m3\u001b[39m, \u001b[32m6\u001b[39m, \u001b[32m8\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(\u001b[33m'\u001b[39m\u001b[33minf\u001b[39m\u001b[33m'\u001b[39m)],\n\u001b[32m      4\u001b[39m     labels=[\u001b[33m'\u001b[39m\u001b[33mbad\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmoderate\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mgood\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mexcellent\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      5\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nour\\Desktop\\Project\\Project2\\code-quality-assessor\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nour\\Desktop\\Project\\Project2\\code-quality-assessor\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'quality_score'"
     ]
    }
   ],
   "source": [
    "df['quality_label'] = pd.cut(\n",
    "    df['quality_score'],\n",
    "    bins=[-float('inf'), 3, 6, 8, float('inf')],\n",
    "    labels=['bad', 'moderate', 'good', 'excellent']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "quality_label\n",
      "bad          8\n",
      "moderate     1\n",
      "good         1\n",
      "excellent    0\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(df['quality_label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 6: Train-Test Split\n",
    "\n",
    "After scoring and labeling, we divide the dataset into **training** and **testing** subsets:\n",
    "- **80%** of the data is used for training,\n",
    "- **20%** is reserved for testing,\n",
    "- We use `stratify=y` to maintain class proportions.\n",
    "\n",
    "This split ensures that we can evaluate model performance fairly and avoid data leakage.\n",
    "\n",
    "We will later save the splits into `data/processed/` for reuse during model training and evaluation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[286]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m X = df.drop(columns=[\u001b[33m'\u001b[39m\u001b[33mquality_score\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mquality_label\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      4\u001b[39m y = df[\u001b[33m'\u001b[39m\u001b[33mquality_label\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m X_train, X_test, y_train, y_test = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstratify\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nour\\Desktop\\Project\\Project2\\code-quality-assessor\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nour\\Desktop\\Project\\Project2\\code-quality-assessor\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2872\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[39m\n\u001b[32m   2868\u001b[39m         CVClass = ShuffleSplit\n\u001b[32m   2870\u001b[39m     cv = CVClass(test_size=n_test, train_size=n_train, random_state=random_state)\n\u001b[32m-> \u001b[39m\u001b[32m2872\u001b[39m     train, test = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstratify\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2874\u001b[39m train, test = ensure_common_namespace_device(arrays[\u001b[32m0\u001b[39m], train, test)\n\u001b[32m   2876\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[32m   2877\u001b[39m     chain.from_iterable(\n\u001b[32m   2878\u001b[39m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[32m   2879\u001b[39m     )\n\u001b[32m   2880\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nour\\Desktop\\Project\\Project2\\code-quality-assessor\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:1909\u001b[39m, in \u001b[36mBaseShuffleSplit.split\u001b[39m\u001b[34m(self, X, y, groups)\u001b[39m\n\u001b[32m   1879\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[32m   1880\u001b[39m \n\u001b[32m   1881\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1906\u001b[39m \u001b[33;03mto an integer.\u001b[39;00m\n\u001b[32m   1907\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1908\u001b[39m X, y, groups = indexable(X, y, groups)\n\u001b[32m-> \u001b[39m\u001b[32m1909\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iter_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1910\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nour\\Desktop\\Project\\Project2\\code-quality-assessor\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2318\u001b[39m, in \u001b[36mStratifiedShuffleSplit._iter_indices\u001b[39m\u001b[34m(self, X, y, groups)\u001b[39m\n\u001b[32m   2316\u001b[39m class_counts = np.bincount(y_indices)\n\u001b[32m   2317\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.min(class_counts) < \u001b[32m2\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2318\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2319\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe least populated class in y has only 1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2320\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m member, which is too few. The minimum\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2321\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m number of groups for any class cannot\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m be less than 2.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2323\u001b[39m     )\n\u001b[32m   2325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_train < n_classes:\n\u001b[32m   2326\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2327\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe train_size = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m should be greater or \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2328\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mequal to the number of classes = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m\"\u001b[39m % (n_train, n_classes)\n\u001b[32m   2329\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns=['quality_score', 'quality_label'])\n",
    "y = df['quality_label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 7: Feature Preprocessing – Scaling and Encoding\n",
    "\n",
    "Now that we’ve labeled our dataset, the next step is to **prepare the features** for use in machine learning models.\n",
    "\n",
    "### Why this step is important:\n",
    "- Some models, like **Neural Networks** and **Transformers**, are sensitive to the scale of input features.\n",
    "- **Random Forests** don’t need scaling, but we’ll preprocess everything uniformly to keep workflows consistent.\n",
    "- Boolean features like `has_docstring` and `uses_globals` can be used directly (0 or 1), but must be properly handled in the pipeline.\n",
    "\n",
    "### What we’ll do:\n",
    "- **Scale** all numerical features using `StandardScaler` (mean = 0, std = 1).\n",
    "- **Pass through** all boolean features (they're already numeric).\n",
    "\n",
    "We use `ColumnTransformer` to apply different preprocessing steps to different columns.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate numeric and boolean features\n",
    "numeric_features = df.select_dtypes(include=['int64', 'float64']).drop(columns=['quality_score']).columns.tolist()\n",
    "boolean_features = df.select_dtypes(include=['bool']).columns.tolist()\n",
    "\n",
    "# Create preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),  # Scale numeric features\n",
    "        ('bool', 'passthrough', boolean_features)     # Keep boolean features as-is\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 8: Train-Test Split and Dataset Saving\n",
    "\n",
    "Once the features are ready, we’ll split the dataset into **training** and **testing** sets.\n",
    "\n",
    "### Why we do this:\n",
    "- To **evaluate** model performance fairly.\n",
    "- To **prevent data leakage** — the model should never \"see\" the test data during training.\n",
    "- To **reuse** the same splits for all models and experiments.\n",
    "\n",
    "### What we’ll do:\n",
    "- Split 80% for training, 20% for testing using `train_test_split()`.\n",
    "- Use `stratify=y` to preserve class proportions across splits.\n",
    "- Save the resulting datasets (`X_train`, `X_test`, `y_train`, `y_test`) to the `data/processed/` folder so they can be easily loaded later in the training and evaluation notebooks.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the features and target \n",
    "X = df.drop(columns=['quality_score', 'quality_label'])\n",
    "y = df['quality_label']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "X_train.to_csv(\"../data/processed/X_train.csv\", index=False)\n",
    "X_test.to_csv(\"../data/processed/X_test.csv\", index=False)\n",
    "y_train.to_csv(\"../data/processed/y_train.csv\", index=False)\n",
    "y_test.to_csv(\"../data/processed/y_test.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
